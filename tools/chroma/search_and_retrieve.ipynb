{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up chroma in memeory\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a collection, as in collection of documents\n",
    "collection = client.create_collection('sea_creatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding documents to the collection along with source and ids\n",
    "# Note: we may use the source information to filter by source eg: private/public later\n",
    "collection.add(\n",
    "    documents=[\"Leopard Shark\", \"Blue Whale\", \"Great White\", \"Dolphin\", \"Seal\", \"Whale Shark\"], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "    metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"},{\"source\": \"notion\"}, {\"source\": \"google-docs\"},{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # filter on these!\n",
    "    ids=[\"doc1\", \"doc2\", \"doc3\", \"doc4\", \"doc5\", \"doc6\"], # unique for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Query/search 2 most similar results. You can also .get by id\n",
    "results = collection.query(\n",
    "    query_texts=[\"Shark\"],\n",
    "    n_results=6,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")\n",
    "\n",
    "with open(\"result.json\", \"w\") as fw:\n",
    "    json.dump(results,fw, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observartion:\n",
    "\n",
    "    Great White shark appears at the bottom of the list which concluded that the embedding space couldn't conclude that Great White Shark was closely associated with the term shark - hence either the embeddings didn't capture the meaning from the document well,o or the pre-training needed additional datapoints to work better.\n",
    "\n",
    "    Also the queries here are general knowledge, with private custom data it becomes important for a company to have a custom embedding model generated for them for better results IMO."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
